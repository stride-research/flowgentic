"""
SERVICE_TASK Persistent Service Example

Demonstrates the TRUE behavior of SERVICE_TASK in AsyncFlow:
1. First await returns a FUTURE HANDLE to a persistent service
2. Multiple awaits on the SAME handle return the SAME service instance (no restarts)
3. The service runs in the background until explicitly cancelled
4. New service calls create NEW service instances (cold-start)

Key Proof Points:
- âœ“ Same future handle = Same service instance (incremental counters)
- âœ“ Different futures = Different service instances (reset counters)
- âœ“ Service persists between multiple await calls
- âœ“ Proper lifecycle management with cancel()
"""

import asyncio
from concurrent.futures import ThreadPoolExecutor
from flowgentic.langGraph.main import LangraphIntegration
from flowgentic.langGraph.execution_wrappers import AsyncFlowType
from radical.asyncflow import ConcurrentExecutionBackend
from dotenv import load_dotenv
from .utils.simple_server import SimpleAsyncServer

load_dotenv()


async def main():
	backend = await ConcurrentExecutionBackend(ThreadPoolExecutor())

	async with LangraphIntegration(backend=backend) as agents_manager:
		print("\n" + "=" * 70)
		print("ðŸŽ¯ SERVICE_TASK: Persistent Service Behavior Demo")
		print("=" * 70)

		# SERVICE_TASK that starts a persistent background server
		@agents_manager.execution_wrappers.asyncflow(
			flow_type=AsyncFlowType.SERVICE_TASK
		)
		async def start_api_server(port: int) -> SimpleAsyncServer:
			"""
			Starts a background API server.
			Returns the server instance that persists until cancelled.
			"""
			print(f"ðŸš€ COLD START: Initializing new server on port {port}...")
			server = SimpleAsyncServer(host="localhost", port=port)
			await server.start()
			print(f"âœ… Server {server.instance_id} is now running")
			return server

		# =================================================================
		# PART 1: First service instance - Multiple awaits on same future
		# =================================================================
		print("\n" + "=" * 70)
		print("PART 1: Single Service Instance - Persistence Proof")
		print("=" * 70)

		print("\nðŸ”· Step 1: Start first service (await returns the service handle)")
		service_future_1 = await start_api_server(8080)
		print(f"   â†’ Got service future handle: {type(service_future_1)}")

		# Await the future to get the actual server instance
		print("\nðŸ”· Step 2: Await the future to get server instance")
		server_1 = await service_future_1
		print(f"   â†’ Server instance: {server_1.instance_id}")
		print(f"   â†’ Port: {server_1.port}")

		# Make first request
		print("\nðŸ”· Step 3: Make first request")
		result_1 = await server_1.handle_request("/api/data", "GET")
		print(f"   ðŸ“¡ Request #{result_1['request_number']}")
		print(f"   Server: {result_1['instance_id']}")
		print(f"   Uptime: {result_1['uptime_seconds']:.2f}s")

		await asyncio.sleep(0.5)

		# Make second request - SAME future, SAME server
		print("\nðŸ”· Step 4: Make second request (same server instance)")
		result_2 = await server_1.handle_request("/api/users", "GET")
		print(f"   ðŸ“¡ Request #{result_2['request_number']}")
		print(f"   Server: {result_2['instance_id']}")
		print(f"   Uptime: {result_2['uptime_seconds']:.2f}s")

		await asyncio.sleep(0.5)

		# Make third request
		print("\nðŸ”· Step 5: Make third request (still same server)")
		result_3 = await server_1.handle_request("/api/health", "POST")
		print(f"   ðŸ“¡ Request #{result_3['request_number']}")
		print(f"   Server: {result_3['instance_id']}")
		print(f"   Uptime: {result_3['uptime_seconds']:.2f}s")

		# =================================================================
		# PROOF OF PERSISTENCE
		# =================================================================
		print("\n" + "=" * 70)
		print("âœ… PROOF: Same service instance persisted across multiple requests")
		print("=" * 70)
		print(f"   All requests used same server: {result_1['instance_id']}")
		print(
			f"   Request counter incremented: {result_1['request_number']} â†’ {result_2['request_number']} â†’ {result_3['request_number']}"
		)
		print(
			f"   Uptime increased: {result_1['uptime_seconds']:.2f}s â†’ {result_3['uptime_seconds']:.2f}s"
		)
		print(f"   Only ONE 'COLD START' message appeared")

		# =================================================================
		# PART 2: New service call creates NEW instance
		# =================================================================
		print("\n" + "=" * 70)
		print("PART 2: New Service Call - Cold Start Proof")
		print("=" * 70)

		print("\nðŸ”· Step 6: Start SECOND service (different port)")
		service_future_2 = await start_api_server(8081)
		server_2 = await service_future_2

		print(f"\nðŸ”· Step 7: Make request to second server")
		result_4 = await server_2.handle_request("/api/metrics", "GET")
		print(f"   ðŸ“¡ Request #{result_4['request_number']}")
		print(f"   Server: {result_4['instance_id']}")
		print(f"   Uptime: {result_4['uptime_seconds']:.2f}s")

		print("\n" + "=" * 70)
		print("âœ… PROOF: New service call created NEW instance")
		print("=" * 70)
		print(f"   Server 1 ID: {result_1['instance_id']}")
		print(f"   Server 2 ID: {result_4['instance_id']}")
		print(
			f"   Different instances: {result_1['instance_id'] != result_4['instance_id']}"
		)
		print(f"   Counter RESET in new server: Request #{result_4['request_number']}")
		print(f"   SECOND 'COLD START' message appeared")

		# =================================================================
		# PART 3: Original server STILL RUNNING after new one started
		# =================================================================
		print("\n" + "=" * 70)
		print("PART 3: Both Services Running Concurrently")
		print("=" * 70)

		print("\nðŸ”· Step 8: Make another request to FIRST server")
		result_5 = await server_1.handle_request("/api/status", "GET")
		print(f"   ðŸ“¡ Request #{result_5['request_number']}")
		print(f"   Server: {result_5['instance_id']}")
		print(f"   Uptime: {result_5['uptime_seconds']:.2f}s")

		print("\nðŸ”· Step 9: Make another request to SECOND server")
		result_6 = await server_2.handle_request("/api/info", "GET")
		print(f"   ðŸ“¡ Request #{result_6['request_number']}")
		print(f"   Server: {result_6['instance_id']}")
		print(f"   Uptime: {result_6['uptime_seconds']:.2f}s")

		print("\n" + "=" * 70)
		print("âœ… PROOF: Both services running independently")
		print("=" * 70)
		print(
			f"   Server 1: {result_5['request_number']} total requests (counter at {result_5['request_number']})"
		)
		print(
			f"   Server 2: {result_6['request_number']} total requests (counter at {result_6['request_number']})"
		)
		print(f"   Both maintained separate state and uptime")

		# =================================================================
		# PART 4: Cleanup - Cancel services
		# =================================================================
		print("\n" + "=" * 70)
		print("ðŸ›‘ CLEANUP: Shutting down services")
		print("=" * 70)

		print("\nðŸ”· Step 10: Cancel first service")
		service_future_1.cancel()
		await server_1.shutdown()
		print(f"   âœ“ Server 1 ({server_1.instance_id}) shut down")

		print("\nðŸ”· Step 11: Cancel second service")
		service_future_2.cancel()
		await server_2.shutdown()
		print(f"   âœ“ Server 2 ({server_2.instance_id}) shut down")

		# =================================================================
		# SUMMARY
		# =================================================================
		print("\n" + "=" * 70)
		print("ðŸ“‹ SERVICE_TASK BEHAVIOR SUMMARY")
		print("=" * 70)
		print("1. await service_task() â†’ Returns a FUTURE handle")
		print("2. await future â†’ Gets the persistent service instance")
		print("3. Multiple awaits on SAME future â†’ SAME service (no restart)")
		print("4. Service runs in background until cancelled")
		print("5. New service call â†’ NEW instance (cold-start)")
		print("6. Use case: Database pools, API servers, ML models in memory")
		print("=" * 70)


if __name__ == "__main__":
	asyncio.run(main())
